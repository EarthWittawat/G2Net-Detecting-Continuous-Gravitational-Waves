{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EarthWittawat/G2Net-Detecting-Continuous-Gravitational-Waves/blob/main/g2net_detecting_continuous_gravitational_wav.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install timm -q"
      ],
      "metadata": {
        "id": "lpdvOOeAahXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import h5py\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio\n",
        "import torchvision.transforms as TF\n",
        "\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from timm.scheduler import CosineLRScheduler\n",
        "\n",
        "device = torch.device('cuda')\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Train metadata\n",
        "di = '../input/g2net-detecting-continuous-gravitational-waves'\n",
        "df = pd.read_csv(di + '/train_labels.csv')\n",
        "df = df[df.target >= 0]  # Remove 3 unknowns (target = -1)"
      ],
      "metadata": {
        "id": "5hITa6LTahXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_time_mask = nn.Sequential(\n",
        "                torchaudio.transforms.TimeMasking(time_mask_param=10),\n",
        "            )\n",
        "\n",
        "transforms_freq_mask = nn.Sequential(\n",
        "                torchaudio.transforms.FrequencyMasking(freq_mask_param=10),\n",
        "            )\n",
        "\n",
        "flip_rate = 0.0 # probability of applying the horizontal flip and vertical flip \n",
        "fre_shift_rate = 0.0 # probability of applying the vertical shift\n",
        "\n",
        "time_mask_num = 0 # number of time masking\n",
        "freq_mask_num = 0 # number of frequency masking"
      ],
      "metadata": {
        "id": "iU-6W-snahXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    dataset = Dataset(data_type, df)\n",
        "\n",
        "    img, y = dataset[i]\n",
        "      img (np.float32): 2 x 360 x 128\n",
        "      y (np.float32): label 0 or 1\n",
        "    \"\"\"\n",
        "    def __init__(self, data_type, df, tfms=False):\n",
        "        self.data_type = data_type\n",
        "        self.df = df\n",
        "        self.tfms = tfms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \"\"\"\n",
        "        i (int): get ith data\n",
        "        \"\"\"\n",
        "        r = self.df.iloc[i]\n",
        "        y = np.float32(r.target)\n",
        "        file_id = r.id\n",
        "\n",
        "        img = np.empty((2, 360, 128), dtype=np.float32)\n",
        "\n",
        "        filename = '%s/%s/%s.hdf5' % (di, self.data_type, file_id)\n",
        "        with h5py.File(filename, 'r') as f:\n",
        "            g = f[file_id]\n",
        "\n",
        "            for ch, s in enumerate(['H1', 'L1']):\n",
        "                a = g[s]['SFTs'][:, :4096] * 1e22  # Fourier coefficient complex64\n",
        "\n",
        "                p = a.real**2 + a.imag**2  # power\n",
        "                p /= np.mean(p)  # normalize\n",
        "                p = np.mean(p.reshape(360, 128, 32), axis=2)  # compress 4096 -> 128\n",
        "                img[ch] = p\n",
        "\n",
        "        if self.tfms:\n",
        "            if np.random.rand() <= flip_rate: # horizontal flip\n",
        "                img = np.flip(img, axis=1).copy()\n",
        "            if np.random.rand() <= flip_rate: # vertical flip\n",
        "                img = np.flip(img, axis=2).copy()\n",
        "            if np.random.rand() <= fre_shift_rate: # vertical shift\n",
        "                img = np.roll(img, np.random.randint(low=0, high=img.shape[1]), axis=1)\n",
        "            \n",
        "            img = torch.from_numpy(img)\n",
        "\n",
        "            for _ in range(time_mask_num): # tima masking\n",
        "                img = transforms_time_mask(img)\n",
        "            for _ in range(freq_mask_num): # frequency masking\n",
        "                img = transforms_freq_mask(img)\n",
        "        \n",
        "        else:\n",
        "            img = torch.from_numpy(img)\n",
        "                \n",
        "        return img, y"
      ],
      "metadata": {
        "id": "rHq-FzuGahXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset('train', df, tfms=False)\n",
        "img, y = dataset[10]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.title('Spectrogram')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('frequency')\n",
        "plt.imshow(img[0, 0:360])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "flip_rate = 1.0 # probability of applying the horizontal flip and vertical flip \n",
        "\n",
        "dataset = Dataset('train', df, tfms=True)\n",
        "img, y = dataset[10]\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.title('Spectrogram')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('frequency')\n",
        "plt.imshow(img[0, 0:360])\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vu396pZMahXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset('train', df, tfms=False)\n",
        "img, y = dataset[10]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.title('Spectrogram')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('frequency')\n",
        "plt.imshow(img[0, 0:360])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "flip_rate = 0.0 # probability of applying the horizontal flip and vertical flip \n",
        "fre_shift_rate = 1.0 # probability of applying the vertical shift\n",
        "\n",
        "dataset = Dataset('train', df, tfms=True)\n",
        "img, y = dataset[10]\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.title('Spectrogram')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('frequency')\n",
        "plt.imshow(img[0, 0:360])\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "00CvZccJahXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset('train', df, tfms=False)\n",
        "img, y = dataset[10]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.title('Spectrogram')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('frequency')\n",
        "plt.imshow(img[0, 0:360])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "flip_rate = 0.0 # probability of applying the horizontal flip and vertical flip \n",
        "fre_shift_rate = 0.0 # probability of applying the vertical shift\n",
        "time_mask_num = 3 # number of time masking\n",
        "\n",
        "dataset = Dataset('train', df, tfms=True)\n",
        "img, y = dataset[10]\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.title('Spectrogram')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('frequency')\n",
        "plt.imshow(img[0, 0:360])\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1u6r-p6IahXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset('train', df, tfms=False)\n",
        "img, y = dataset[10]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.title('Spectrogram')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('frequency')\n",
        "plt.imshow(img[0, 0:360])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "flip_rate = 0.0 # probability of applying the horizontal flip and vertical flip \n",
        "fre_shift_rate = 0.0 # probability of applying the vertical shift\n",
        "time_mask_num = 3 # number of time masking\n",
        "\n",
        "dataset = Dataset('train', df, tfms=True)\n",
        "img, y = dataset[10]\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.title('Spectrogram')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('frequency')\n",
        "plt.imshow(img[0, 0:360])\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NOLf3FgTahXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, name, *, pretrained=False):\n",
        "        \"\"\"\n",
        "        name (str): timm model name, e.g. tf_efficientnet_b2_ns\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Use timm\n",
        "        model = timm.create_model(name, pretrained=pretrained, in_chans=2)\n",
        "\n",
        "        clsf = model.default_cfg['classifier']\n",
        "        n_features = model._modules[clsf].in_features\n",
        "        model._modules[clsf] = nn.Identity()\n",
        "\n",
        "        self.fc = nn.Linear(n_features, 1)\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "_21EIcNvahXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader_val, *, compute_score=True, pbar=None):\n",
        "    \"\"\"\n",
        "    Predict and compute loss and score\n",
        "    \"\"\"\n",
        "    tb = time.time()\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "\n",
        "    loss_sum = 0.0\n",
        "    n_sum = 0\n",
        "    y_all = []\n",
        "    y_pred_all = []\n",
        "\n",
        "    if pbar is not None:\n",
        "        pbar = tqdm(desc='Predict', nrows=78, total=pbar)\n",
        "\n",
        "    for img, y in loader_val:\n",
        "        n = y.size(0)\n",
        "        img = img.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "                y_pred = model(img.to(device))\n",
        "\n",
        "        loss = criterion(y_pred.view(-1), y)\n",
        "\n",
        "        n_sum += n\n",
        "        loss_sum += n * loss.item()\n",
        "\n",
        "        y_all.append(y.cpu().detach().numpy())\n",
        "        y_pred_all.append(y_pred.sigmoid().squeeze().cpu().detach().numpy())\n",
        "\n",
        "        if pbar is not None:\n",
        "            pbar.update(len(img))\n",
        "        \n",
        "        del loss, y_pred, img, y\n",
        "\n",
        "    loss_val = loss_sum / n_sum\n",
        "\n",
        "    y = np.concatenate(y_all)\n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "\n",
        "    score = roc_auc_score(y, y_pred) if compute_score else None\n",
        "\n",
        "    ret = {'loss': loss_val,\n",
        "           'score': score,\n",
        "           'y': y,\n",
        "           'y_pred': y_pred,\n",
        "           'time': time.time() - tb}\n",
        "    \n",
        "    model.train(was_training)  # back to train from eval if necessary\n",
        "\n",
        "    return ret"
      ],
      "metadata": {
        "id": "GVvhk4QcahXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'tf_efficientnet_b7_ns'\n",
        "nfold = 5\n",
        "kfold = KFold(n_splits=nfold, random_state=42, shuffle=True)\n",
        "\n",
        "epochs = 35\n",
        "batch_size = 16\n",
        "num_workers = 2\n",
        "weight_decay = 1e-6\n",
        "max_grad_norm = 1000\n",
        "\n",
        "lr_max = 4e-4\n",
        "epochs_warmup = 1.0\n",
        "\n",
        "\n",
        "## setting of audio data augmentation \n",
        "flip_rate = 0.5 # probability of applying the horizontal flip and vertical flip \n",
        "fre_shift_rate = 1.0 # probability of applying the vertical shift\n",
        "time_mask_num = 1 # number of time masking\n",
        "freq_mask_num = 2 # number of frequency masking\n",
        "\n",
        "for ifold, (idx_train, idx_test) in enumerate(kfold.split(df)):\n",
        "    print('Fold %d/%d' % (ifold, nfold))\n",
        "    torch.manual_seed(42 + ifold + 1)\n",
        "\n",
        "    # Train - val split\n",
        "    dataset_train = Dataset('train', df.iloc[idx_train], tfms=True)\n",
        "    dataset_val = Dataset('train', df.iloc[idx_test])\n",
        "\n",
        "    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size,\n",
        "                     num_workers=num_workers, pin_memory=True, shuffle=True, drop_last=True)\n",
        "    loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size,\n",
        "                     num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    # Model and optimizer\n",
        "    model = Model(model_name, pretrained=True)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr_max, weight_decay=weight_decay)\n",
        "\n",
        "    # Learning-rate schedule\n",
        "    nbatch = len(loader_train)\n",
        "    warmup = epochs_warmup * nbatch  # number of warmup steps\n",
        "    nsteps = epochs * nbatch        # number of total steps\n",
        "\n",
        "    scheduler = CosineLRScheduler(optimizer,\n",
        "                  warmup_t=warmup, warmup_lr_init=0.0, warmup_prefix=True, # 1 epoch of warmup\n",
        "                  t_initial=(nsteps - warmup), lr_min=1e-6)                # 3 epochs of cosine\n",
        "    \n",
        "    time_val = 0.0\n",
        "    lrs = []\n",
        "\n",
        "    tb = time.time()\n",
        "    print('Epoch   loss          score   lr')\n",
        "    for iepoch in range(epochs):\n",
        "        loss_sum = 0.0\n",
        "        n_sum = 0\n",
        "\n",
        "        # Train\n",
        "        for ibatch, (img, y) in enumerate(loader_train):\n",
        "            n = y.size(0)\n",
        "            img = img.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred = model(img)\n",
        "            loss = criterion(y_pred.view(-1), y)\n",
        "\n",
        "            loss_train = loss.item()\n",
        "            loss_sum += n * loss_train\n",
        "            n_sum += n\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
        "                                                       max_grad_norm)\n",
        "            optimizer.step()\n",
        "            \n",
        "            scheduler.step(iepoch * nbatch + ibatch + 1)\n",
        "            lrs.append(optimizer.param_groups[0]['lr'])            \n",
        "\n",
        "        # Evaluate\n",
        "        val = evaluate(model, loader_val)\n",
        "        time_val += val['time']\n",
        "        loss_train = loss_sum / n_sum\n",
        "        lr_now = optimizer.param_groups[0]['lr']\n",
        "        dt = (time.time() - tb) / 60\n",
        "        print('Epoch %d %.4f %.4f %.4f  %.2e  %.2f min' %\n",
        "              (iepoch + 1, loss_train, val['loss'], val['score'], lr_now, dt))\n",
        "\n",
        "    dt = time.time() - tb\n",
        "    print('Training done %.2f min total, %.2f min val' % (dt / 60, time_val / 60))\n",
        "\n",
        "    # Save model\n",
        "    ofilename = 'model%d.pytorch' % ifold\n",
        "    torch.save(model.state_dict(), ofilename)\n",
        "    print(ofilename, 'written')\n",
        "\n",
        "    break  # 1 fold only"
      ],
      "metadata": {
        "id": "snTeH4NCahXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('LR Schedule: Cosine with linear warmup')\n",
        "plt.xlabel('steps')\n",
        "plt.ylabel('learning rate')\n",
        "plt.plot(lrs)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4jncCOIhahXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wU07-RUUahXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model (if necessary)\n",
        "model = Model(model_name, pretrained=False)\n",
        "filename = 'model0.pytorch'\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(filename, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# Predict\n",
        "submit = pd.read_csv(di + '/sample_submission.csv')\n",
        "dataset_test = Dataset('test', submit)\n",
        "loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=64,\n",
        "                                    num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "test = evaluate(model, loader_test, compute_score=False, pbar=len(submit))\n",
        "\n",
        "# Write prediction\n",
        "submit['target'] = test['y_pred']\n",
        "submit.to_csv('submission.csv', index=False)\n",
        "print('target range [%.2f, %.2f]' % (submit['target'].min(), submit['target'].max()))"
      ],
      "metadata": {
        "id": "ZQNj41HQahXs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}